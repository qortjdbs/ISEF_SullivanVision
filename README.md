<h1>Emotion Recognition Device for Visually Impaired (EBED011T)</h1>

<br>

<img src = "ISEF_POSTER.png"></img>


<body>
    <p><strong><h3>Abstract</h3></strong></p>
    <p>
        Globally, more than 2.2 billion people suffer from visual impairment, according to the World Health Organization (WHO). Communication is an essential aspect of everyday life, and for visually impaired individuals, interpreting emotions during conversations can be a challenge. Our project aims to develop an emotion recognition device that can benefit visually impaired individuals in their conversations. We have integrated effective speech emotion recognition (SER) and facial expression recognition (FER) models with portable hardware to enable real-time emotion interpretation during discussions.
    </p>
    <p>
        Our SER model achieved 97.25% accuracy in validation when trained on large datasets, while our FER model scored 98.55%. By combining these AI-driven models with hardware, we have developed a device that detects verbal and visual cues and wirelessly transmits data for analysis. The device offers different levels of vibrations for categorized emotions, allowing visually impaired users to classify emotions more objectively. The headband and glasses design of the device enables hands-free use for the users, and it can be connected wirelessly to a smartphone for portability. The product price is estimated to be $30, which is affordable compared to previously developed products in the industry.
    </p>
    <p>
        In conclusion, our device marks a significant step forward in combining AI and hardware integration to improve communication for visually impaired individuals. The ability to understand emotions in speech is crucial for fruitful communication, and our technology encourages connections between the visually impaired and the world, enabling them to manage social encounters more effectively.
    </p>
</body>
</html>
